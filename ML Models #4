ğŸ¤– ML Basics #4: Evaluation Metrics

ğŸ“˜ Description

ãƒ¢ãƒ‡ãƒ«ã®è‰¯ã—æ‚ªã—ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã«ä½¿ã†æŒ‡æ¨™ã‚’**è©•ä¾¡æŒ‡æ¨™ï¼ˆmetricsï¼‰**ã¨ã„ã†ã€‚
å›å¸°ãƒ»åˆ†é¡ã§ä½¿ã†æŒ‡æ¨™ãŒé•ã†ã€‚


---

ğŸ“ ä¸»ãªè©•ä¾¡æŒ‡æ¨™

ğŸ”¹ å›å¸°ï¼ˆæ•°å€¤äºˆæ¸¬ï¼‰

MAE (Mean Absolute Error)ï¼šèª¤å·®ã®çµ¶å¯¾å€¤ã®å¹³å‡ã€‚å°ã•ã„ã»ã©è‰¯ã„ã€‚

MSE (Mean Squared Error)ï¼šèª¤å·®ã‚’äºŒä¹—ã—ã¦å¹³å‡ã€‚å¤–ã‚Œå€¤ã«æ•æ„Ÿã€‚

RÂ²ã‚¹ã‚³ã‚¢ï¼š1ã«è¿‘ã„ã»ã©è‰¯ã„ï¼ˆæ±ºå®šä¿‚æ•°ï¼‰ã€‚


ğŸ”¹ åˆ†é¡ï¼ˆãƒ©ãƒ™ãƒ«äºˆæ¸¬ï¼‰

Accuracyï¼ˆæ­£è§£ç‡ï¼‰ï¼šå…¨ä½“ã®ã†ã¡æ­£è§£ã—ãŸå‰²åˆã€‚

Precisionï¼ˆé©åˆç‡ï¼‰ï¼šäºˆæ¸¬ã—ãŸæ­£ã®ã†ã¡æ­£è§£ã ã£ãŸå‰²åˆã€‚

Recallï¼ˆå†ç¾ç‡ï¼‰ï¼šå®Ÿéš›ã«æ­£ã®ã‚‚ã®ã®ã†ã¡äºˆæ¸¬ã§å½“ã¦ã‚‰ã‚ŒãŸå‰²åˆã€‚

F1-scoreï¼šPrecisionã¨Recallã®ãƒãƒ©ãƒ³ã‚¹ã€‚



---

ğŸ–‹ï¸ Sample Code (å›å¸°)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# å®Ÿæ¸¬å€¤ã¨äºˆæ¸¬å€¤
y_true = np.array([3, 5, 7])
y_pred = np.array([2.8, 5.2, 6.5])

print("MAE:", mean_absolute_error(y_true, y_pred))
print("MSE:", mean_squared_error(y_true, y_pred))
print("RÂ²:", r2_score(y_true, y_pred))

ğŸ–‹ï¸ Sample Code (åˆ†é¡)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_true = [1, 0, 1, 1, 0]
y_pred = [1, 0, 0, 1, 1]

print("Accuracy:", accuracy_score(y_true, y_pred))
print("Precision:", precision_score(y_true, y_pred))
print("Recall:", recall_score(y_true, y_pred))
print("F1-score:", f1_score(y_true, y_pred))


---

ğŸ’¡ Key Points

ãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ã«ã‚ˆã£ã¦é©åˆ‡ãªæŒ‡æ¨™ã‚’ä½¿ã„åˆ†ã‘ã‚‹ã€‚

å˜ã«ã€Œæ­£è§£ç‡ãŒé«˜ã„ï¼è‰¯ã„ãƒ¢ãƒ‡ãƒ«ã€ã§ã¯ãªã„ã‚±ãƒ¼ã‚¹ã‚‚å¤šã„ã€‚

ç‰¹ã«ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹: 90%ãŒãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã§ã¯F1-scoreãªã©ãŒé‡è¦ã€‚



---

ğŸ¯ Mini Challenge

ãƒ»y_trueã¨y_predã®å€¤ã‚’å¤‰ãˆã¦ã€Accuracyãƒ»Precisionãƒ»Recallãƒ»F1ãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹è©¦ã—ã¦ã¿ã‚ˆã†ã€‚