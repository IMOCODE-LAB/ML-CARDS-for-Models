ğŸ¤– ML Basics #5: Overfitting and Underfitting

ğŸ“˜ Description

Overfittingï¼ˆéå­¦ç¿’ï¼‰
ã€€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã¯é«˜ç²¾åº¦ã ã‘ã©ã€æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã§ã¯ç²¾åº¦ãŒã‚¬ã‚¿è½ã¡ã™ã‚‹çŠ¶æ…‹ã€‚
ã€€ï¼ˆæš—è¨˜ã—ã™ãã¦ãƒ†ã‚¹ãƒˆã«å¼±ã„æ„Ÿã˜ğŸ“šï¼‰

Underfittingï¼ˆå­¦ç¿’ä¸è¶³ï¼‰
ã€€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã™ã‚‰ã†ã¾ããƒ•ã‚£ãƒƒãƒˆã—ã¦ã„ãªã„çŠ¶æ…‹ã€‚
ã€€ï¼ˆå‹‰å¼·é‡ãŒè¶³ã‚Šãšãƒ†ã‚¹ãƒˆã‚‚ã§ããªã„æ„Ÿã˜ğŸ“šï¼‰


âš–ï¸ Signs

çŠ¶æ…‹	å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç²¾åº¦	ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç²¾åº¦	åŸå› ä¾‹

Overfitting	é«˜ã„	ä½ã„	ãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ã™ãã‚‹
Underfitting	ä½ã„	ä½ã„	ãƒ¢ãƒ‡ãƒ«ãŒå˜ç´”ã™ãã‚‹ï¼ãƒ‡ãƒ¼ã‚¿ä¸è¶³


ğŸ–‹ï¸ Sample Code (scikit-learn)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# éå­¦ç¿’æ°—å‘³ãªæ·±ã„æœ¨
deep_tree = DecisionTreeClassifier(max_depth=None)  # åˆ¶é™ãªã—
deep_tree.fit(X_train, y_train)
print("Deep Tree Test Score:", deep_tree.score(X_test, y_test))

# é€†ã«æµ…ã™ãã‚‹æœ¨
shallow_tree = DecisionTreeClassifier(max_depth=1)
shallow_tree.fit(X_train, y_train)
print("Shallow Tree Test Score:", shallow_tree.score(X_test, y_test))

ğŸ’¡ Key Points

éå­¦ç¿’ã‚’é˜²ãã«ã¯ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’åˆ¶å¾¡ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãƒ»æ­£å‰‡åŒ–ãªã©ï¼‰ã€‚

ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ãƒ»ç‰¹å¾´é‡ã‚’æ•´ç†ã™ã‚‹ã®ã‚‚æœ‰åŠ¹ã€‚

å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã§ç²¾åº¦ã‚’æ¯”è¼ƒã—ã¦è¦‹æŠœãã€‚


ğŸ¯ Mini Challenge

ãƒ»max_depthã‚’2ã‚„3ã«å¤‰ãˆã¦ã€ç²¾åº¦ãŒã©ã†å¤‰ã‚ã‚‹ã‹è©¦ã—ã¦ã¿ã‚ˆã†ã€‚